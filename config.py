"""
å…¨å±€é…ç½®æ–‡ä»¶
ç®¡ç†æ¨¡å‹ã€MCP æœåŠ¡å™¨ã€ä¸šåŠ¡å‚æ•°ç­‰é…ç½®
"""

import os
from typing import Dict, Any
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# ========== æ¨¡å‹é…ç½® ==========

class ModelConfig:
    """å¤šæ¨¡å‹ååŒé…ç½®"""
    
    # æ¨¡å‹è§’è‰²åˆ†é…
    # ğŸ’¡ æç¤ºï¼šå¦‚æœä½¿ç”¨ç¬¬ä¸‰æ–¹å¹³å°ï¼ˆå¦‚ OpenRouterã€SiliconFlow ç­‰ï¼‰ï¼Œ
    #         å¯ä»¥åœ¨ .env ä¸­é…ç½® OPENAI_BASE_URLï¼Œç„¶åç›´æ¥ä½¿ç”¨ä»»ä½•æ¨¡å‹åç§°
    #         ç³»ç»Ÿä¼šè‡ªåŠ¨é€šè¿‡ OpenAI å…¼å®¹æ¥å£è°ƒç”¨ï¼ˆåŒ…æ‹¬ Claudeã€GPTã€Gemini ç­‰ï¼‰
    MODELS = {
        "reasoning": {
            "name": "gpt-4o",
            "provider": "openai",  # å¦‚æœç”¨ç¬¬ä¸‰æ–¹å¹³å°ï¼Œä¼šè‡ªåŠ¨èµ° OpenAI å…¼å®¹æ¥å£
            "description": "æ·±åº¦æ¨ç†ã€ç­–ç•¥åˆ¶å®š",
            "use_cases": ["content_analysis", "strategy", "complex_reasoning"]
        },
        "creative": {
            "name": "claude-3-5-sonnet-20241022",  # ä½¿ç”¨ç¬¬ä¸‰æ–¹å¹³å°æ”¯æŒçš„æœ€æ–°ç‰ˆæœ¬
            "provider": "anthropic",  # å¦‚æœç”¨ç¬¬ä¸‰æ–¹å¹³å°ï¼Œä¼šè‡ªåŠ¨èµ° OpenAI å…¼å®¹æ¥å£
            "description": "åˆ›æ„å†™ä½œã€æ ‡é¢˜ç”Ÿæˆ",
            "use_cases": ["title_generation", "creative_writing", "storytelling"]
        },
        "fast": {
            "name": "gpt-4o-mini",
            "provider": "openai",
            "description": "å¿«é€Ÿä»»åŠ¡ã€è¯„åˆ†",
            "use_cases": ["review", "scoring", "simple_tasks"]
        },
        "vision": {
            "name": "qwen2.5-vl",
            "provider": "custom",
            "description": "å¤šæ¨¡æ€ç†è§£ã€å›¾åƒåˆ†æ",
            "use_cases": ["image_analysis", "ocr", "image_text_matching"]
        },
        "local": {
            "name": "llama3.2",
            "provider": "ollama",
            "description": "æœ¬åœ°éšç§ä»»åŠ¡",
            "use_cases": ["compliance_check", "sensitive_data"]
        }
    }
    
    # API Keys å’Œ Base URLs
    OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
    OPENAI_BASE_URL = os.getenv("OPENAI_BASE_URL")  # å¯é€‰ï¼Œç”¨äºç¬¬ä¸‰æ–¹ API
    
    ANTHROPIC_API_KEY = os.getenv("ANTHROPIC_API_KEY")
    OLLAMA_BASE_URL = os.getenv("OLLAMA_BASE_URL", "http://localhost:11434/v1")
    
    # ç¬¬ä¸‰æ–¹å¹³å°é…ç½®ç¤ºä¾‹
    # å¦‚æœä½¿ç”¨ç¬¬ä¸‰æ–¹å¹³å°ï¼ˆå¦‚ OpenRouter, ç¡…åŸºæµåŠ¨ç­‰ï¼‰ï¼Œåªéœ€é…ç½® OPENAI_API_KEY å’Œ OPENAI_BASE_URL
    # ç„¶ååœ¨ä¸‹é¢çš„ MODELS ä¸­æŒ‡å®šå¯ç”¨çš„æ¨¡å‹åç§°
    
    # æ”¯æŒçš„ç¬¬ä¸‰æ–¹å¹³å°ç¤ºä¾‹ï¼š
    THIRD_PARTY_PLATFORMS = {
        "openrouter": {
            "base_url": "https://openrouter.ai/api/v1",
            "models": ["gpt-4o", "claude-3.5-sonnet", "llama-3.1-70b", "deepseek-chat"],
            "description": "ä¸€ä¸ª API è®¿é—®å¤šä¸ªæ¨¡å‹"
        },
        "siliconflow": {
            "base_url": "https://api.siliconflow.cn/v1",
            "models": ["Qwen/Qwen2.5-7B-Instruct", "deepseek-ai/DeepSeek-V2.5", "claude-3-5-sonnet"],
            "description": "å›½å†…é«˜æ€§ä»·æ¯”å¹³å°"
        },
        "groq": {
            "base_url": "https://api.groq.com/openai/v1",
            "models": ["llama-3.1-70b-versatile", "mixtral-8x7b-32768"],
            "description": "è¶…å¿«æ¨ç†é€Ÿåº¦"
        },
        "deepseek": {
            "base_url": "https://api.deepseek.com/v1",
            "models": ["deepseek-chat", "deepseek-coder"],
            "description": "å›½äº§é«˜æ€§ä»·æ¯”æ¨¡å‹"
        },
        "moonshot": {
            "base_url": "https://api.moonshot.cn/v1",
            "models": ["moonshot-v1-8k", "moonshot-v1-32k", "moonshot-v1-128k"],
            "description": "Kimi æ¨¡å‹"
        }
    }
    
    # å¤‡ç”¨æ¨¡å‹ï¼ˆé™çº§ç­–ç•¥ï¼‰
    FALLBACK_MODELS = {
        "gpt-4o": "gpt-4o-mini",
        "claude-3-5-sonnet-20241022": "gpt-4o",
        "claude-3.5-sonnet": "gpt-4o",  # å…¼å®¹æ—§é…ç½®
        "qwen2.5-vl": "gpt-4o-vision",
        "gpt-4o-mini": None,  # å·²ç»æ˜¯æœ€ä¾¿å®œçš„ï¼Œæ— æ³•ç»§ç»­é™çº§
    }
    
    # ä»»åŠ¡ç±»å‹åˆ°æ¨¡å‹çš„æ˜ å°„
    # æ”¯æŒä¸‰ç§è´¨é‡çº§åˆ«ï¼šfastï¼ˆå¿«é€Ÿï¼‰ã€balancedï¼ˆå¹³è¡¡ï¼‰ã€highï¼ˆé«˜è´¨é‡ï¼‰
    TASK_MODEL_MAPPING = {
        "analysis": {
            "fast": "gpt-4o-mini",
            "balanced": "gpt-4o",
            "high": "gpt-4o"
        },
        "creation": {
            "fast": "gpt-4o-mini",
            "balanced": "claude-3-5-sonnet-20241022",  # æœ€æ–°ç‰ˆ Claude 3.5 Sonnet
            "high": "claude-3-5-sonnet-20241022"
        },
        "review": {
            "fast": "gpt-4o-mini",
            "balanced": "gpt-4o-mini",
            "high": "gpt-4o"
        },
        "reasoning": {
            "fast": "gpt-4o-mini",
            "balanced": "gpt-4o",
            "high": "gpt-4o"
        },
        "vision": {
            "fast": "gpt-4o-vision",
            "balanced": "qwen2.5-vl",
            "high": "gpt-4o-vision"
        }
    }
    
    # æ¨¡å‹è¯¦ç»†ä¿¡æ¯ï¼ˆæè¿°ã€ç‰¹ç‚¹ã€æœ€ä½³ç”¨é€”ï¼‰
    MODEL_INFO = {
        "gpt-4o": {
            "provider": "openai",
            "description": "OpenAI æœ€æ–°æ——èˆ°æ¨¡å‹",
            "strengths": ["æ·±åº¦æ¨ç†", "å¤æ‚é—®é¢˜æ±‚è§£", "ç­–ç•¥åˆ¶å®š"],
            "cost_level": "high",
            "context_window": 128000
        },
        "gpt-4o-mini": {
            "provider": "openai",
            "description": "GPT-4o çš„è½»é‡ç‰ˆæœ¬",
            "strengths": ["å¿«é€Ÿå“åº”", "æˆæœ¬ä½", "é€‚åˆç®€å•ä»»åŠ¡"],
            "cost_level": "low",
            "context_window": 128000
        },
        "claude-3-5-sonnet-20241022": {
            "provider": "anthropic",
            "description": "Claude 3.5 Sonnet æœ€æ–°ç‰ˆ (2024-10-22)",
            "strengths": ["åˆ›æ„å†™ä½œ", "é•¿æ–‡æœ¬ç”Ÿæˆ", "è‡ªç„¶å¯¹è¯", "ä»£ç ç”Ÿæˆ"],
            "cost_level": "high",
            "context_window": 200000
        },
        "claude-3.5-sonnet": {
            "provider": "anthropic",
            "description": "Claude 3.5 Sonnet (é€šç”¨åˆ«å)",
            "strengths": ["åˆ›æ„å†™ä½œ", "é•¿æ–‡æœ¬ç”Ÿæˆ", "è‡ªç„¶å¯¹è¯"],
            "cost_level": "high",
            "context_window": 200000
        },
        "qwen2.5-vl": {
            "provider": "custom",
            "description": "é€šä¹‰åƒé—®è§†è§‰è¯­è¨€æ¨¡å‹",
            "strengths": ["å›¾ç‰‡ç†è§£", "å¤šæ¨¡æ€åˆ†æ", "OCR"],
            "cost_level": "medium",
            "context_window": 32000
        },
        "gpt-4o-vision": {
            "provider": "openai",
            "description": "GPT-4o è§†è§‰ç‰ˆæœ¬",
            "strengths": ["å›¾ç‰‡ç†è§£", "è§†è§‰åˆ†æ"],
            "cost_level": "high",
            "context_window": 128000
        }
    }
    
    @classmethod
    def get_api_config(cls) -> Dict[str, Any]:
        """
        è·å– API é…ç½®ï¼Œç”¨äºåˆå§‹åŒ– Agent
        
        Returns:
            åŒ…å« API Key å’Œ Base URL çš„å­—å…¸
        """
        config = {}
        
        if cls.OPENAI_API_KEY:
            config['api_key'] = cls.OPENAI_API_KEY
        
        if cls.OPENAI_BASE_URL:
            config['base_url'] = cls.OPENAI_BASE_URL
        
        return config
    
    @classmethod
    def validate_config(cls) -> Dict[str, Any]:
        """
        éªŒè¯é…ç½®å®Œæ•´æ€§å’Œæ­£ç¡®æ€§
        
        Returns:
            éªŒè¯ç»“æœå­—å…¸ï¼ŒåŒ…å« success, errors, warnings
        """
        result = {
            "success": True,
            "errors": [],
            "warnings": []
        }
        
        # 1. æ£€æŸ¥è‡³å°‘æœ‰ä¸€ä¸ªLLM APIé…ç½®
        has_llm = False
        
        if cls.OPENAI_API_KEY:
            has_llm = True
            # éªŒè¯API Keyæ ¼å¼
            if not cls.OPENAI_API_KEY.startswith(('sk-', 'sess-')):
                result["warnings"].append(
                    "OpenAI API Key æ ¼å¼å¯èƒ½ä¸æ­£ç¡®ï¼ˆé€šå¸¸ä»¥ sk- æˆ– sess- å¼€å¤´ï¼‰"
                )
        
        if cls.ANTHROPIC_API_KEY:
            has_llm = True
            if not cls.ANTHROPIC_API_KEY.startswith('sk-'):
                result["warnings"].append(
                    "Anthropic API Key æ ¼å¼å¯èƒ½ä¸æ­£ç¡®ï¼ˆé€šå¸¸ä»¥ sk- å¼€å¤´ï¼‰"
                )
        
        if cls.OLLAMA_BASE_URL:
            has_llm = True
        
        if not has_llm:
            result["errors"].append(
                "è‡³å°‘éœ€è¦é…ç½®ä¸€ä¸ª LLM APIï¼ˆOpenAIã€Anthropic æˆ– Ollamaï¼‰"
            )
            result["success"] = False
        
        # 2. æ£€æŸ¥å…³é”®æ¨¡å‹é…ç½®
        required_models = ["reasoning", "creative", "fast"]
        for model_type in required_models:
            if model_type not in cls.MODELS:
                result["errors"].append(f"ç¼ºå°‘å…³é”®æ¨¡å‹é…ç½®: {model_type}")
                result["success"] = False
        
        # 3. æ£€æŸ¥é™çº§é“¾å®Œæ•´æ€§
        for model, fallback in cls.FALLBACK_MODELS.items():
            if fallback and fallback not in cls.MODEL_INFO:
                result["warnings"].append(
                    f"æ¨¡å‹ {model} çš„é™çº§æ¨¡å‹ {fallback} æœªåœ¨ MODEL_INFO ä¸­å®šä¹‰"
                )
        
        # 4. æ£€æŸ¥ä»»åŠ¡æ¨¡å‹æ˜ å°„
        for task_type, quality_models in cls.TASK_MODEL_MAPPING.items():
            for quality_level, model_name in quality_models.items():
                if model_name not in cls.MODEL_INFO:
                    result["warnings"].append(
                        f"ä»»åŠ¡ {task_type}/{quality_level} é…ç½®çš„æ¨¡å‹ {model_name} "
                        f"æœªåœ¨ MODEL_INFO ä¸­å®šä¹‰"
                    )
        
        return result
    
    @classmethod
    def check_model_available(cls, model_name: str) -> bool:
        """
        æ£€æŸ¥æ¨¡å‹æ˜¯å¦å¯ç”¨
        
        Args:
            model_name: æ¨¡å‹åç§°
        
        Returns:
            æ˜¯å¦å¯ç”¨
        """
        # æ£€æŸ¥æ¨¡å‹æ˜¯å¦åœ¨ MODEL_INFO ä¸­
        if model_name not in cls.MODEL_INFO:
            return False
        
        model_info = cls.MODEL_INFO[model_name]
        provider = model_info.get("provider")
        
        # æ ¹æ®æä¾›å•†æ£€æŸ¥APIé…ç½®
        if provider == "openai":
            return cls.OPENAI_API_KEY is not None
        elif provider == "anthropic":
            return cls.ANTHROPIC_API_KEY is not None
        elif provider == "ollama":
            return cls.OLLAMA_BASE_URL is not None
        elif provider == "custom":
            # è‡ªå®šä¹‰æ¨¡å‹éœ€è¦è‡³å°‘ä¸€ä¸ªAPIé…ç½®
            return cls.OPENAI_API_KEY is not None or cls.ANTHROPIC_API_KEY is not None
        
        return False
    
    @classmethod
    def get_available_models(cls) -> Dict[str, bool]:
        """
        è·å–æ‰€æœ‰æ¨¡å‹çš„å¯ç”¨æ€§çŠ¶æ€
        
        Returns:
            æ¨¡å‹åç§°åˆ°å¯ç”¨æ€§çš„æ˜ å°„
        """
        return {
            model_name: cls.check_model_available(model_name)
            for model_name in cls.MODEL_INFO.keys()
        }
    
    @classmethod
    def print_config_summary(cls):
        """æ‰“å°é…ç½®æ‘˜è¦ï¼ˆç”¨äºè°ƒè¯•ï¼‰"""
        print("\n" + "=" * 60)
        print("ğŸ“‹ æ¨¡å‹é…ç½®æ‘˜è¦")
        print("=" * 60)
        
        # APIé…ç½®
        print("\nğŸ”‘ APIé…ç½®:")
        print(f"  OpenAI API: {'âœ… å·²é…ç½®' if cls.OPENAI_API_KEY else 'âŒ æœªé…ç½®'}")
        if cls.OPENAI_BASE_URL:
            print(f"  Base URL: {cls.OPENAI_BASE_URL}")
        print(f"  Anthropic API: {'âœ… å·²é…ç½®' if cls.ANTHROPIC_API_KEY else 'âŒ æœªé…ç½®'}")
        print(f"  Ollama: {'âœ… å·²é…ç½®' if cls.OLLAMA_BASE_URL else 'âŒ æœªé…ç½®'}")
        
        # æ¨¡å‹å¯ç”¨æ€§
        print("\nğŸ¤– æ¨¡å‹å¯ç”¨æ€§:")
        available_models = cls.get_available_models()
        for model_name, is_available in available_models.items():
            status = "âœ…" if is_available else "âŒ"
            print(f"  {status} {model_name}")
        
        print("\n" + "=" * 60 + "\n")


# ========== MCP æœåŠ¡å™¨é…ç½® ==========

class MCPConfig:
    """MCP æœåŠ¡å™¨é›†æˆé…ç½®"""
    
    SERVERS = {
        "xiaohongshu": {
            "url": os.getenv("MCP_XIAOHONGSHU_URL", "http://localhost:18060"),
            "enabled": True,
            "timeout": 30,
            "methods": {
                "fetch_top_posts": "è·å–çƒ­é—¨å¸–å­",
                "search_posts": "æœç´¢å¸–å­",
                "publish_post": "å‘å¸ƒå¸–å­",
                "get_post_stats": "è·å–å¸–å­ç»Ÿè®¡"
            }
        },
        "image_gen": {
            "url": os.getenv("MCP_IMAGE_GEN_URL", "http://localhost:8002"),
            "enabled": True,
            "timeout": 120,  # å›¾ç‰‡ç”Ÿæˆå¯èƒ½éœ€è¦æ›´é•¿æ—¶é—´
            "methods": {
                "generate_dalle": "DALL-E 3 ç”Ÿæˆ",
                "generate_midjourney": "Midjourney ç”Ÿæˆ",
                "fetch_unsplash": "Unsplash æœç´¢",
                "fetch_pexels": "Pexels æœç´¢"
            }
        },
        "multimodal": {
            "url": os.getenv("MCP_MULTIMODAL_URL", "http://localhost:8003"),
            "enabled": True,
            "timeout": 30,
            "methods": {
                "analyze_image": "å›¾åƒåˆ†æ",
                "extract_text": "OCR æ–‡å­—æå–",
                "check_image_quality": "å›¾ç‰‡è´¨é‡æ£€æŸ¥",
                "match_image_text": "å›¾æ–‡åŒ¹é…åº¦è¯„ä¼°"
            }
        },
        "compliance": {
            "url": os.getenv("MCP_COMPLIANCE_URL", "http://localhost:8004"),
            "enabled": True,
            "timeout": 10,
            "methods": {
                "check_sensitive_words": "æ•æ„Ÿè¯æ£€æµ‹",
                "check_advertising_law": "å¹¿å‘Šæ³•æ£€æŸ¥",
                "check_platform_rules": "å¹³å°è§„åˆ™æ£€æŸ¥"
            }
        }
    }
    
    # MCP è°ƒç”¨é‡è¯•é…ç½®
    RETRY_CONFIG = {
        "max_retries": 3,
        "retry_delay": 2,  # ç§’
        "exponential_backoff": True
    }


# ========== ä¸šåŠ¡é…ç½® ==========

class BusinessConfig:
    """ä¸šåŠ¡é€»è¾‘é…ç½®"""
    
    # å†…å®¹åˆ†æé…ç½®
    CONTENT_ANALYSIS = {
        "top_n_posts": 5,  # åˆ†æå‰ N ç¯‡çƒ­é—¨å¸–å­
        "min_likes": 0,  # æœ€ä½ç‚¹èµé‡ï¼ˆ0=ä¸è¿‡æ»¤ï¼‰
        "max_posts_age_days": 30,  # æœ€è¿‘ N å¤©çš„å¸–å­
        "analysis_dimensions": [
            "title_style",
            "content_structure",
            "image_style",
            "emotional_tone",
            "engagement_triggers"
        ]
    }
    
    # å›¾ç‰‡ç”Ÿæˆé…ç½®
    IMAGE_GENERATION = {
        "count": 7,  # é»˜è®¤ç”Ÿæˆå›¾ç‰‡æ•°é‡
        "min_count": 5,
        "max_count": 9,
        "aspect_ratio": "9:16",  # å°çº¢ä¹¦æ¨èæ¯”ä¾‹
        "quality": "hd",
        "style_preferences": [
            "natural",
            "bright",
            "high_saturation"
        ]
    }
    
    # å†…å®¹åˆ›ä½œé…ç½®
    CONTENT_CREATION = {
        "title_length": (15, 25),  # æ ‡é¢˜å­—æ•°èŒƒå›´
        "content_length": (800, 1200),  # æ­£æ–‡å­—æ•°èŒƒå›´
        "tags_count": (5, 8),  # æ ‡ç­¾æ•°é‡
        "emoji_density": 0.05,  # emoji å¯†åº¦ï¼ˆæ¯ 100 å­—ï¼‰
        "paragraph_count": (5, 8)  # æ®µè½æ•°é‡
    }
    
    # è¯„å®¡é…ç½®
    REVIEW = {
        "threshold": 8.0,  # é€šè¿‡é˜ˆå€¼
        "max_revisions": 3,  # æœ€å¤šä¿®æ”¹æ¬¡æ•°
        "weights": {  # å„è¯„å®¡ç»´åº¦æƒé‡
            "engagement": 0.4,
            "quality": 0.35,
            "compliance": 0.25
        },
        "dimensions": {
            "engagement": [
                "title_attractiveness",
                "content_usefulness",
                "emotional_resonance",
                "interaction_triggers"
            ],
            "quality": [
                "grammar",
                "logic",
                "originality",
                "readability"
            ],
            "compliance": [
                "sensitive_words",
                "advertising_law",
                "platform_rules"
            ]
        }
    }
    
    # å‘å¸ƒé…ç½®
    PUBLISHING = {
        "auto_publish": False,  # æ˜¯å¦è‡ªåŠ¨å‘å¸ƒ
        "require_confirmation": True,  # æ˜¯å¦éœ€è¦äººå·¥ç¡®è®¤
        "save_drafts": True,  # æ˜¯å¦ä¿å­˜è‰ç¨¿
        "draft_retention_days": 30  # è‰ç¨¿ä¿ç•™å¤©æ•°
    }


# ========== Agent é…ç½® ==========

class AgentConfig:
    """Agent æ‰§è¡Œé…ç½®"""
    
    # ä¸»åè°ƒ Agent
    COORDINATOR = {
        "name": "social_media_coordinator",
        "max_iterations": 30,
        "model": "gpt-5-mini-2025-08-07",  # å¿«é€Ÿå†³ç­–ã€æˆæœ¬ä½
        "temperature": 0.7
    }
    
    # å­ Agent é…ç½®ï¼ˆå·²æ ¹æ®å¹³å°å¯ç”¨æ¨¡å‹ä¼˜åŒ–ï¼‰
    SUB_AGENTS = {
        "content_analyst": {
            "model": "claude-3-7-sonnet-20250219",  # Claude 3.7ï¼šæœ€å¼ºåˆ†ææ¨ç†
            "temperature": 0.5,
            "max_tokens": 4000
        },
        "image_generator": {
            "model": "Qwen/Qwen3-VL-32B-Instruct",  # Qwen 3 VLï¼šå¤šæ¨¡æ€è§†è§‰
            "temperature": 0.8,
            "max_tokens": 2000
        },
        "content_creator": {
            "model": "claude-opus-4-1-20250805",  # Claude Opus 4.1ï¼šæœ€å¼ºåˆ›æ„å†™ä½œ
            "temperature": 0.9,
            "max_tokens": 5000  # å¢åŠ é™åˆ¶ï¼Œç¡®ä¿èƒ½ç”Ÿæˆå®Œæ•´çš„å†…å®¹ï¼ˆåŒ…æ‹¬ image_suggestionsï¼‰
        },
        "reviewer_engagement": {
            "model": "claude-sonnet-4-20250514",  # Claude Sonnet 4ï¼šä¼˜ç§€çš„æ•°æ®åˆ†æ
            "temperature": 0.3,
            "max_tokens": 1000
        },
        "reviewer_quality": {
            "model": "gpt-4o-mini",  # æ”¹ç”¨ GPT-4o-miniï¼šå¿«é€Ÿã€ç¨³å®šã€æˆæœ¬ä½
            "temperature": 0.3,
            "max_tokens": 1000
        },
        "reviewer_compliance": {
            "model": "gpt-4.1-mini-2025-04-14",  # GPT-4.1 Miniï¼šå¿«é€Ÿåˆè§„æ£€æŸ¥
            "temperature": 0.1,
            "max_tokens": 1000
        }
    }


# ========== è·¯å¾„é…ç½® ==========

class PathConfig:
    """æ–‡ä»¶è·¯å¾„é…ç½®"""
    
    from pathlib import Path as _Path
    
    BASE_DIR = _Path(__file__).parent.absolute()
    
    # è¾“å‡ºç›®å½•
    OUTPUTS_DIR = BASE_DIR / "outputs"
    IMAGES_DIR = OUTPUTS_DIR / "images"
    DRAFTS_DIR = OUTPUTS_DIR / "drafts"
    LOGS_DIR = OUTPUTS_DIR / "logs"
    
    # æç¤ºè¯ç›®å½•
    PROMPTS_DIR = BASE_DIR / "prompts"
    
    # ç¡®ä¿ç›®å½•å­˜åœ¨
    @classmethod
    def ensure_dirs(cls):
        """ç¡®ä¿æ‰€æœ‰è¾“å‡ºç›®å½•å­˜åœ¨"""
        for dir_path in [cls.IMAGES_DIR, cls.DRAFTS_DIR, cls.LOGS_DIR]:
            dir_path.mkdir(parents=True, exist_ok=True)


# ========== æ—¥å¿—é…ç½® ==========

class LogConfig:
    """æ—¥å¿—ç³»ç»Ÿé…ç½®"""
    
    LEVEL = os.getenv("LOG_LEVEL", "INFO")
    FORMAT = "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
    DATE_FORMAT = "%Y-%m-%d %H:%M:%S"
    
    # æ—¥å¿—æ–‡ä»¶
    FILE_ENABLED = True
    FILE_PATH = PathConfig.LOGS_DIR / "agent.log"
    FILE_MAX_BYTES = 10 * 1024 * 1024  # 10MB
    FILE_BACKUP_COUNT = 5
    
    # æ§åˆ¶å°è¾“å‡º
    CONSOLE_ENABLED = True
    CONSOLE_COLORIZE = True


# ========== æ€§èƒ½é…ç½® ==========

class PerformanceConfig:
    """æ€§èƒ½ä¼˜åŒ–é…ç½®"""
    
    # ç¼“å­˜é…ç½®
    CACHE_ENABLED = True
    CACHE_TTL = 86400  # 24 å°æ—¶
    CACHE_MAX_SIZE = 1000
    
    # å¹¶è¡Œæ‰§è¡Œ
    PARALLEL_REVIEWS = True  # è¯„å®¡æ˜¯å¦å¹¶è¡Œ
    MAX_WORKERS = 3  # æœ€å¤§å¹¶è¡Œæ•°
    
    # è¶…æ—¶é…ç½®
    TIMEOUT = {
        "llm_call": 60,  # LLM è°ƒç”¨è¶…æ—¶
        "mcp_call": 30,  # MCP è°ƒç”¨è¶…æ—¶
        "image_gen": 120,  # å›¾ç‰‡ç”Ÿæˆè¶…æ—¶
        "total_workflow": 600  # æ•´ä½“æµç¨‹è¶…æ—¶ï¼ˆ10åˆ†é’Ÿï¼‰
    }


# ========== å¼€å‘é…ç½® ==========

class DevConfig:
    """å¼€å‘å’Œè°ƒè¯•é…ç½®"""
    
    DEBUG = os.getenv("DEBUG", "false").lower() == "true"
    VERBOSE = os.getenv("VERBOSE", "false").lower() == "true"
    
    # æ¨¡æ‹Ÿæ¨¡å¼ï¼ˆä¸è°ƒç”¨çœŸå® APIï¼‰
    MOCK_MODE = os.getenv("MOCK_MODE", "false").lower() == "true"
    
    # è·³è¿‡æŸäº›æ­¥éª¤ï¼ˆæµ‹è¯•ç”¨ï¼‰
    SKIP_IMAGE_GENERATION = False
    SKIP_PUBLISHING = True  # é»˜è®¤ä¸è‡ªåŠ¨å‘å¸ƒ
    
    # æµ‹è¯•æ•°æ®
    TEST_KEYWORD = "æ¾³æ´²æ—…æ¸¸"
    TEST_OUTPUT_DIR = PathConfig.BASE_DIR / "test_outputs"


# ========== å¯¼å‡ºé…ç½® ==========

# åˆå§‹åŒ–ç›®å½•
PathConfig.ensure_dirs()

# å¯¼å‡ºæ‰€æœ‰é…ç½®
__all__ = [
    "ModelConfig",
    "MCPConfig",
    "BusinessConfig",
    "AgentConfig",
    "PathConfig",
    "LogConfig",
    "PerformanceConfig",
    "DevConfig"
]

