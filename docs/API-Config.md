# API æ–‡æ¡£ - é…ç½®å‚è€ƒ

æœ¬æ–‡æ¡£è¯¦ç»†è¯´æ˜ Social Media Agent ç³»ç»Ÿçš„æ‰€æœ‰é…ç½®é¡¹ã€‚

---

## ğŸ“‹ ç›®å½•

1. [ç¯å¢ƒå˜é‡é…ç½®](#ç¯å¢ƒå˜é‡é…ç½®)
2. [æ¨¡å‹é…ç½®](#æ¨¡å‹é…ç½®)
3. [Agent é…ç½®](#agent-é…ç½®)
4. [MCP æœåŠ¡é…ç½®](#mcp-æœåŠ¡é…ç½®)
5. [ä¸šåŠ¡é…ç½®](#ä¸šåŠ¡é…ç½®)
6. [æ€§èƒ½é…ç½®](#æ€§èƒ½é…ç½®)
7. [å¼€å‘é…ç½®](#å¼€å‘é…ç½®)

---

## ç¯å¢ƒå˜é‡é…ç½®

### `.env` æ–‡ä»¶

å¤åˆ¶ `env.example` åˆ›å»ºä½ çš„é…ç½®æ–‡ä»¶ï¼š

```bash
cp env.example .env
```

### å¿…éœ€é…ç½®

```bash
# ========== API Keys ==========
# ä½¿ç”¨ç¬¬ä¸‰æ–¹ OpenAI å…¼å®¹ API å¹³å°
OPENAI_API_KEY=your-api-key-here
OPENAI_BASE_URL=https://api.example.com/v1

# ========== MCP Server ==========
MCP_XIAOHONGSHU_URL=http://localhost:18060
```

### å¯é€‰é…ç½®

```bash
# ========== ä¸šåŠ¡é…ç½® ==========
REVIEW_THRESHOLD=8.0          # è¯„å®¡é€šè¿‡é˜ˆå€¼ (0-10åˆ†)
MAX_REVISIONS=3               # æœ€å¤§ä¿®æ”¹æ¬¡æ•°
AUTO_PUBLISH=false            # æ˜¯å¦è‡ªåŠ¨å‘å¸ƒ

# ========== å¼€å‘é…ç½® ==========
DEBUG=false                   # è°ƒè¯•æ¨¡å¼
VERBOSE=false                 # è¯¦ç»†æ—¥å¿—
MOCK_MODE=false               # æ¨¡æ‹Ÿæ¨¡å¼ï¼ˆä¸è°ƒç”¨çœŸå® APIï¼‰
LOG_LEVEL=INFO                # æ—¥å¿—çº§åˆ« (DEBUG, INFO, WARNING, ERROR)
```

---

## æ¨¡å‹é…ç½®

### `ModelConfig` ç±»

ä½ç½®ï¼š`config.py`

### æ”¯æŒçš„æ¨¡å‹

```python
MODELS = {
    "reasoning": {
        "name": "gpt-4o",
        "provider": "openai",
        "description": "æ·±åº¦æ¨ç†ã€ç­–ç•¥åˆ¶å®š"
    },
    "creative": {
        "name": "claude-3-5-sonnet-20241022",
        "provider": "anthropic",
        "description": "åˆ›æ„å†™ä½œã€æ ‡é¢˜ç”Ÿæˆ"
    },
    "fast": {
        "name": "gpt-4o-mini",
        "provider": "openai",
        "description": "å¿«é€Ÿä»»åŠ¡ã€è¯„åˆ†"
    },
    "vision": {
        "name": "qwen2.5-vl",
        "provider": "custom",
        "description": "å¤šæ¨¡æ€ç†è§£ã€å›¾åƒåˆ†æ"
    },
    "local": {
        "name": "llama3.2",
        "provider": "ollama",
        "description": "æœ¬åœ°éšç§ä»»åŠ¡"
    }
}
```

### ä»»åŠ¡ç±»å‹åˆ°æ¨¡å‹çš„æ˜ å°„

```python
TASK_MODEL_MAPPING = {
    "analysis": {
        "fast": "gpt-4o-mini",
        "balanced": "gpt-4o",
        "high": "gpt-4o"
    },
    "creation": {
        "fast": "gpt-4o-mini",
        "balanced": "claude-3-5-sonnet-20241022",
        "high": "claude-3-5-sonnet-20241022"
    },
    "review": {
        "fast": "gpt-4o-mini",
        "balanced": "gpt-4o-mini",
        "high": "gpt-4o"
    }
}
```

### é™çº§ç­–ç•¥é…ç½®

```python
FALLBACK_MODELS = {
    "gpt-4o": "gpt-4o-mini",
    "claude-3-5-sonnet-20241022": "gpt-4o",
    "gpt-4o-mini": None  # æ— å¤‡ç”¨
}
```

### æ¨¡å‹è¯¦ç»†ä¿¡æ¯

```python
MODEL_INFO = {
    "gpt-4o": {
        "provider": "openai",
        "description": "OpenAI æœ€æ–°æ——èˆ°æ¨¡å‹",
        "strengths": ["æ·±åº¦æ¨ç†", "å¤æ‚é—®é¢˜æ±‚è§£", "ç­–ç•¥åˆ¶å®š"],
        "cost_level": "high",
        "context_window": 128000
    },
    "gpt-4o-mini": {
        "provider": "openai",
        "description": "GPT-4o çš„è½»é‡ç‰ˆæœ¬",
        "strengths": ["å¿«é€Ÿå“åº”", "æˆæœ¬ä½", "é€‚åˆç®€å•ä»»åŠ¡"],
        "cost_level": "low",
        "context_window": 128000
    },
    "claude-3-5-sonnet-20241022": {
        "provider": "anthropic",
        "description": "Claude 3.5 Sonnet æœ€æ–°ç‰ˆ",
        "strengths": ["åˆ›æ„å†™ä½œ", "é•¿æ–‡æœ¬ç”Ÿæˆ", "è‡ªç„¶å¯¹è¯"],
        "cost_level": "high",
        "context_window": 200000
    }
}
```

### ä½¿ç”¨æ–¹å¼

```python
from config import ModelConfig

# è·å– API é…ç½®
api_config = ModelConfig.get_api_config()
# è¿”å›ï¼š{"api_key": "...", "base_url": "..."}

# è®¿é—®æ¨¡å‹é…ç½®
models = ModelConfig.MODELS
task_mapping = ModelConfig.TASK_MODEL_MAPPING
fallbacks = ModelConfig.FALLBACK_MODELS
```

---

## Agent é…ç½®

### `AgentConfig` ç±»

ä½ç½®ï¼š`config.py`

### Coordinator Agent é…ç½®

```python
COORDINATOR = {
    "name": "social_media_coordinator",
    "max_iterations": 30,
    "model": "gpt-5-mini-2025-08-07",  # å¿«é€Ÿå†³ç­–ã€æˆæœ¬ä½
    "temperature": 0.7
}
```

### å­ Agent é…ç½®

```python
SUB_AGENTS = {
    "content_analyst": {
        "model": "claude-3-7-sonnet-20250219",  # Claude 3.7ï¼šæœ€å¼ºåˆ†ææ¨ç†
        "temperature": 0.5,
        "max_tokens": 4000
    },
    "content_creator": {
        "model": "claude-opus-4-1-20250805",  # Claude Opus 4.1ï¼šæœ€å¼ºåˆ›æ„å†™ä½œ
        "temperature": 0.9,
        "max_tokens": 3000
    },
    "reviewer_engagement": {
        "model": "claude-sonnet-4-20250514",  # Claude Sonnet 4ï¼šä¼˜ç§€çš„æ•°æ®åˆ†æ
        "temperature": 0.3,
        "max_tokens": 1000
    },
    "reviewer_quality": {
        "model": "claude-sonnet-4-20250514",  # Claude Sonnet 4ï¼šå‡†ç¡®çš„è´¨é‡è¯„ä¼°
        "temperature": 0.3,
        "max_tokens": 1000
    },
    "reviewer_compliance": {
        "model": "gpt-4.1-mini-2025-04-14",  # GPT-4.1 Miniï¼šå¿«é€Ÿåˆè§„æ£€æŸ¥
        "temperature": 0.1,
        "max_tokens": 1000
    }
}
```

### ä½¿ç”¨æ–¹å¼

```python
from config import AgentConfig

# è·å– Coordinator é…ç½®
coord_config = AgentConfig.COORDINATOR
model = coord_config["model"]
max_iter = coord_config["max_iterations"]

# è·å–å­ Agent é…ç½®
creator_config = AgentConfig.SUB_AGENTS["content_creator"]
model_name = creator_config["model"]
temperature = creator_config["temperature"]
```

---

## MCP æœåŠ¡é…ç½®

### `MCPConfig` ç±»

ä½ç½®ï¼š`config.py`

### æœåŠ¡å™¨é…ç½®

```python
SERVERS = {
    "xiaohongshu": {
        "url": "http://localhost:18060",
        "enabled": True,
        "timeout": 30,
        "methods": {
            "fetch_top_posts": "è·å–çƒ­é—¨å¸–å­",
            "search_posts": "æœç´¢å¸–å­",
            "publish_post": "å‘å¸ƒå¸–å­",
            "get_post_stats": "è·å–å¸–å­ç»Ÿè®¡"
        }
    }
}
```

### é‡è¯•é…ç½®

```python
RETRY_CONFIG = {
    "max_retries": 3,
    "retry_delay": 2,  # ç§’
    "exponential_backoff": True
}
```

### ä½¿ç”¨æ–¹å¼

```python
from config import MCPConfig

# è·å–å°çº¢ä¹¦ MCP æœåŠ¡é…ç½®
xhs_config = MCPConfig.SERVERS["xiaohongshu"]
url = xhs_config["url"]
timeout = xhs_config["timeout"]

# è·å–é‡è¯•é…ç½®
retry_config = MCPConfig.RETRY_CONFIG
max_retries = retry_config["max_retries"]
```

---

## ä¸šåŠ¡é…ç½®

### `BusinessConfig` ç±»

ä½ç½®ï¼š`config.py`

### å†…å®¹åˆ†æé…ç½®

```python
CONTENT_ANALYSIS = {
    "top_n_posts": 5,              # åˆ†æå‰ N ç¯‡çƒ­é—¨å¸–å­
    "min_likes": 0,                # æœ€ä½ç‚¹èµé‡ï¼ˆ0=ä¸è¿‡æ»¤ï¼‰
    "max_posts_age_days": 30,      # æœ€è¿‘ N å¤©çš„å¸–å­
    "analysis_dimensions": [
        "title_style",
        "content_structure",
        "image_style",
        "emotional_tone",
        "engagement_triggers"
    ]
}
```

### å›¾ç‰‡ç”Ÿæˆé…ç½®

```python
IMAGE_GENERATION = {
    "count": 7,                    # é»˜è®¤ç”Ÿæˆå›¾ç‰‡æ•°é‡
    "min_count": 5,
    "max_count": 9,
    "aspect_ratio": "9:16",        # å°çº¢ä¹¦æ¨èæ¯”ä¾‹
    "quality": "hd",
    "style_preferences": [
        "natural",
        "bright",
        "high_saturation"
    ]
}
```

### å†…å®¹åˆ›ä½œé…ç½®

```python
CONTENT_CREATION = {
    "title_length": (15, 25),      # æ ‡é¢˜å­—æ•°èŒƒå›´
    "content_length": (800, 1200), # æ­£æ–‡å­—æ•°èŒƒå›´
    "tags_count": (5, 8),          # æ ‡ç­¾æ•°é‡
    "emoji_density": 0.05,         # emoji å¯†åº¦ï¼ˆæ¯ 100 å­—ï¼‰
    "paragraph_count": (5, 8)      # æ®µè½æ•°é‡
}
```

### è¯„å®¡é…ç½®

```python
REVIEW = {
    "threshold": 8.0,              # é€šè¿‡é˜ˆå€¼
    "max_revisions": 3,            # æœ€å¤šä¿®æ”¹æ¬¡æ•°
    "weights": {                   # å„è¯„å®¡ç»´åº¦æƒé‡
        "engagement": 0.4,
        "quality": 0.35,
        "compliance": 0.25
    },
    "dimensions": {
        "engagement": [
            "title_attractiveness",
            "content_usefulness",
            "emotional_resonance",
            "interaction_triggers"
        ],
        "quality": [
            "grammar",
            "logic",
            "originality",
            "readability"
        ]
    }
}
```

### å‘å¸ƒé…ç½®

```python
PUBLISHING = {
    "auto_publish": False,         # æ˜¯å¦è‡ªåŠ¨å‘å¸ƒ
    "require_confirmation": True,  # æ˜¯å¦éœ€è¦äººå·¥ç¡®è®¤
    "save_drafts": True,           # æ˜¯å¦ä¿å­˜è‰ç¨¿
    "draft_retention_days": 30     # è‰ç¨¿ä¿ç•™å¤©æ•°
}
```

### ä½¿ç”¨æ–¹å¼

```python
from config import BusinessConfig

# è·å–å†…å®¹åˆ†æé…ç½®
top_n = BusinessConfig.CONTENT_ANALYSIS["top_n_posts"]

# è·å–è¯„å®¡é˜ˆå€¼
threshold = BusinessConfig.REVIEW["threshold"]

# è·å–å›¾ç‰‡ç”Ÿæˆé…ç½®
img_count = BusinessConfig.IMAGE_GENERATION["count"]
```

---

## æ€§èƒ½é…ç½®

### `PerformanceConfig` ç±»

ä½ç½®ï¼š`config.py`

### ç¼“å­˜é…ç½®

```python
# ç¼“å­˜é…ç½®
CACHE_ENABLED = True
CACHE_TTL = 86400              # 24 å°æ—¶
CACHE_MAX_SIZE = 1000
```

### å¹¶è¡Œæ‰§è¡Œé…ç½®

```python
# å¹¶è¡Œæ‰§è¡Œ
PARALLEL_REVIEWS = True         # è¯„å®¡æ˜¯å¦å¹¶è¡Œ
MAX_WORKERS = 3                 # æœ€å¤§å¹¶è¡Œæ•°
```

### è¶…æ—¶é…ç½®

```python
TIMEOUT = {
    "llm_call": 60,             # LLM è°ƒç”¨è¶…æ—¶
    "mcp_call": 30,             # MCP è°ƒç”¨è¶…æ—¶
    "image_gen": 120,           # å›¾ç‰‡ç”Ÿæˆè¶…æ—¶
    "total_workflow": 600       # æ•´ä½“æµç¨‹è¶…æ—¶ï¼ˆ10åˆ†é’Ÿï¼‰
}
```

### ä½¿ç”¨æ–¹å¼

```python
from config import PerformanceConfig

# æ£€æŸ¥ç¼“å­˜æ˜¯å¦å¯ç”¨
if PerformanceConfig.CACHE_ENABLED:
    ttl = PerformanceConfig.CACHE_TTL
    
# è·å–è¶…æ—¶é…ç½®
llm_timeout = PerformanceConfig.TIMEOUT["llm_call"]
```

---

## è·¯å¾„é…ç½®

### `PathConfig` ç±»

ä½ç½®ï¼š`config.py`

### ç›®å½•é…ç½®

```python
from pathlib import Path

BASE_DIR = Path(__file__).parent.absolute()

# è¾“å‡ºç›®å½•
OUTPUTS_DIR = BASE_DIR / "outputs"
IMAGES_DIR = OUTPUTS_DIR / "images"
DRAFTS_DIR = OUTPUTS_DIR / "drafts"
LOGS_DIR = OUTPUTS_DIR / "logs"

# æç¤ºè¯ç›®å½•
PROMPTS_DIR = BASE_DIR / "prompts"
```

### ä½¿ç”¨æ–¹å¼

```python
from config import PathConfig

# ç¡®ä¿ç›®å½•å­˜åœ¨
PathConfig.ensure_dirs()

# è·å–è·¯å¾„
drafts_dir = PathConfig.DRAFTS_DIR
images_dir = PathConfig.IMAGES_DIR
prompts_dir = PathConfig.PROMPTS_DIR
```

---

## æ—¥å¿—é…ç½®

### `LogConfig` ç±»

ä½ç½®ï¼š`config.py`

### é…ç½®é€‰é¡¹

```python
LEVEL = "INFO"                  # æ—¥å¿—çº§åˆ«
FORMAT = "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
DATE_FORMAT = "%Y-%m-%d %H:%M:%S"

# æ—¥å¿—æ–‡ä»¶
FILE_ENABLED = True
FILE_PATH = PathConfig.LOGS_DIR / "agent.log"
FILE_MAX_BYTES = 10 * 1024 * 1024  # 10MB
FILE_BACKUP_COUNT = 5

# æ§åˆ¶å°è¾“å‡º
CONSOLE_ENABLED = True
CONSOLE_COLORIZE = True
```

### ä½¿ç”¨æ–¹å¼

```python
from config import LogConfig
from utils.logger_config import setup_logging

# è®¾ç½®æ—¥å¿—ç³»ç»Ÿ
setup_logging(
    level=LogConfig.LEVEL,
    console_enabled=LogConfig.CONSOLE_ENABLED,
    file_enabled=LogConfig.FILE_ENABLED,
    colorize=LogConfig.CONSOLE_COLORIZE
)
```

---

## å¼€å‘é…ç½®

### `DevConfig` ç±»

ä½ç½®ï¼š`config.py`

### é…ç½®é€‰é¡¹

```python
DEBUG = False                   # è°ƒè¯•æ¨¡å¼
VERBOSE = False                 # è¯¦ç»†æ—¥å¿—

# æ¨¡æ‹Ÿæ¨¡å¼ï¼ˆä¸è°ƒç”¨çœŸå® APIï¼‰
MOCK_MODE = False

# è·³è¿‡æŸäº›æ­¥éª¤ï¼ˆæµ‹è¯•ç”¨ï¼‰
SKIP_IMAGE_GENERATION = False
SKIP_PUBLISHING = True          # é»˜è®¤ä¸è‡ªåŠ¨å‘å¸ƒ

# æµ‹è¯•æ•°æ®
TEST_KEYWORD = "æ¾³æ´²æ—…æ¸¸"
TEST_OUTPUT_DIR = PathConfig.BASE_DIR / "test_outputs"
```

### ä½¿ç”¨æ–¹å¼

```python
from config import DevConfig

# æ£€æŸ¥æ˜¯å¦ä¸ºè°ƒè¯•æ¨¡å¼
if DevConfig.DEBUG:
    print("è°ƒè¯•æ¨¡å¼å·²å¯ç”¨")
    
# æ£€æŸ¥æ˜¯å¦è·³è¿‡å‘å¸ƒ
if DevConfig.SKIP_PUBLISHING:
    print("è·³è¿‡å‘å¸ƒæ­¥éª¤")
```

---

## é…ç½®æœ€ä½³å®è·µ

### 1. ç¯å¢ƒéš”ç¦»

```bash
# å¼€å‘ç¯å¢ƒ
.env.development

# ç”Ÿäº§ç¯å¢ƒ
.env.production

# æµ‹è¯•ç¯å¢ƒ
.env.test
```

### 2. æ•æ„Ÿä¿¡æ¯ä¿æŠ¤

```bash
# âŒ ä¸è¦å°† .env æäº¤åˆ° Git
echo ".env" >> .gitignore

# âœ… æä¾›ç¤ºä¾‹é…ç½®
cp .env .env.example
# ç„¶ååˆ é™¤ .env.example ä¸­çš„æ•æ„Ÿä¿¡æ¯
```

### 3. é…ç½®éªŒè¯

```python
from config import ModelConfig, MCPConfig

def validate_config():
    """éªŒè¯é…ç½®æ˜¯å¦å®Œæ•´"""
    errors = []
    
    # æ£€æŸ¥ API Key
    if not ModelConfig.OPENAI_API_KEY:
        errors.append("ç¼ºå°‘ OPENAI_API_KEY")
    
    # æ£€æŸ¥ MCP URL
    if not MCPConfig.SERVERS["xiaohongshu"]["url"]:
        errors.append("ç¼ºå°‘ MCP_XIAOHONGSHU_URL")
    
    if errors:
        raise ValueError(f"é…ç½®é”™è¯¯: {', '.join(errors)}")
    
    print("âœ… é…ç½®éªŒè¯é€šè¿‡")

# åœ¨å¯åŠ¨æ—¶è°ƒç”¨
validate_config()
```

### 4. åŠ¨æ€é…ç½®

```python
import os
from config import AgentConfig

# è¿è¡Œæ—¶ä¿®æ”¹é…ç½®
if os.getenv("USE_FAST_MODEL") == "true":
    AgentConfig.COORDINATOR["model"] = "gpt-4o-mini"
```

### 5. é…ç½®å¯¼å‡º

```python
from config import *

def export_config():
    """å¯¼å‡ºå½“å‰é…ç½®ï¼ˆç”¨äºè°ƒè¯•ï¼‰"""
    config = {
        "models": ModelConfig.MODELS,
        "agents": AgentConfig.SUB_AGENTS,
        "business": {
            "review_threshold": BusinessConfig.REVIEW["threshold"],
            "auto_publish": BusinessConfig.PUBLISHING["auto_publish"]
        },
        "performance": {
            "cache_enabled": PerformanceConfig.CACHE_ENABLED,
            "parallel_reviews": PerformanceConfig.PARALLEL_REVIEWS
        }
    }
    
    import json
    print(json.dumps(config, indent=2, ensure_ascii=False))

export_config()
```

---

## ğŸ“š ç›¸å…³æ–‡æ¡£

- [å·¥å…·å‡½æ•°å‚è€ƒ](./API-Tools.md)
- [Agent ä½¿ç”¨æŒ‡å—](./API-Agents.md)
- [æ¶æ„è®¾è®¡](./Architecture.md)

---

**æ›´æ–°æ—¶é—´**: 2025-11-03  
**ç‰ˆæœ¬**: v0.7

