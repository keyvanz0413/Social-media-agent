#!/usr/bin/env python3
"""
Model Router + çœŸå® API é›†æˆæµ‹è¯•
éªŒè¯ Model Router ä¸å®é™… API è°ƒç”¨çš„é›†æˆ
"""

import os
from dotenv import load_dotenv
from utils.model_router import ModelRouter, TaskType, QualityLevel

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

def test_api_integration():
    """æµ‹è¯•ä¸ API çš„é›†æˆ"""
    print("=" * 60)
    print("ğŸ§ª Model Router + API é›†æˆæµ‹è¯•")
    print("=" * 60)
    
    # æ£€æŸ¥ API é…ç½®
    api_key = os.getenv("OPENAI_API_KEY")
    base_url = os.getenv("OPENAI_BASE_URL")
    
    if not api_key:
        print("âŒ æœªé…ç½® OPENAI_API_KEY")
        return False
    
    print(f"âœ… API Key: {api_key[:15]}...{api_key[-4:]}")
    print(f"âœ… Base URL: {base_url or '(é»˜è®¤)'}")
    
    # åˆ›å»ºè·¯ç”±å™¨
    router = ModelRouter()
    
    # æµ‹è¯•ä¸åŒåœºæ™¯çš„æ¨¡å‹é€‰æ‹©
    print("\n" + "=" * 60)
    print("åœºæ™¯æµ‹è¯•")
    print("=" * 60)
    
    scenarios = [
        ("åˆ†æå°çº¢ä¹¦çƒ­é—¨å†…å®¹", TaskType.ANALYSIS, QualityLevel.BALANCED),
        ("åˆ›ä½œæ—…æ¸¸å¸–å­", TaskType.CREATION, QualityLevel.HIGH),
        ("å¿«é€Ÿè¯„å®¡æ–‡æœ¬", TaskType.REVIEW, QualityLevel.FAST),
    ]
    
    for desc, task, quality in scenarios:
        model = router.select_model(task, quality)
        info = router.get_model_info(model)
        
        print(f"\nåœºæ™¯: {desc}")
        print(f"  ä»»åŠ¡ç±»å‹: {task.value}")
        print(f"  è´¨é‡çº§åˆ«: {quality.value}")
        print(f"  é€‰æ‹©æ¨¡å‹: {model}")
        print(f"  æ¨¡å‹æè¿°: {info['description']}")
        print(f"  æˆæœ¬çº§åˆ«: {info['cost_level']}")
        
        # æ˜¾ç¤ºé™çº§é“¾
        fallback = router.get_fallback_model(model)
        if fallback:
            print(f"  å¤‡ç”¨æ¨¡å‹: {fallback}")
    
    # è¯´æ˜å¦‚ä½•åœ¨å®é™…ä»£ç ä¸­ä½¿ç”¨
    print("\n" + "=" * 60)
    print("ä½¿ç”¨ç¤ºä¾‹")
    print("=" * 60)
    
    print("""
# åœ¨ä½ çš„ Agent ä»£ç ä¸­ï¼š
from connectonion import llm_do
from utils.model_router import ModelRouter, TaskType

router = ModelRouter()

# 1. å†…å®¹åˆ†ææ—¶
def analyze_content(keyword):
    model = router.select_model(TaskType.ANALYSIS)
    prompt = f"åˆ†æå…³é”®è¯ '{keyword}' çš„å†…å®¹..."
    result = llm_do(prompt, model=model)
    return result

# 2. å†…å®¹åˆ›ä½œæ—¶
def create_content(analysis):
    model = router.select_model(TaskType.CREATION)
    prompt = f"åŸºäºåˆ†æåˆ›ä½œå†…å®¹ï¼š{analysis}"
    result = llm_do(prompt, model=model)
    return result

# 3. å¸¦é™çº§çš„é”™è¯¯å¤„ç†
def safe_llm_call(prompt, task_type):
    router = ModelRouter()
    model = router.select_model(task_type)
    
    try:
        return llm_do(prompt, model=model)
    except Exception as e:
        # å°è¯•ä½¿ç”¨å¤‡ç”¨æ¨¡å‹
        fallback = router.get_fallback_model(model)
        if fallback:
            print(f"ä¸»æ¨¡å‹å¤±è´¥ï¼Œåˆ‡æ¢åˆ° {fallback}")
            return llm_do(prompt, model=fallback)
        else:
            raise e
    """)
    
    print("\nâœ… é›†æˆæµ‹è¯•å®Œæˆï¼")
    print("\nğŸ’¡ æç¤ºï¼š")
    print("  - Model Router å·²å°±ç»ªï¼Œå¯ä»¥åœ¨ Agent ä¸­ä½¿ç”¨")
    print("  - å®ƒä¼šè‡ªåŠ¨ä½¿ç”¨ä½ é…ç½®çš„ç¬¬ä¸‰æ–¹ API")
    print("  - ä¸‹ä¸€æ­¥ï¼šå®ç° Mock MCP Client")
    
    return True


if __name__ == "__main__":
    test_api_integration()

